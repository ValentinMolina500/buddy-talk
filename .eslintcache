[{"/Users/vmolina/Documents/ProjectsRedux/your-buddy/src/index.js":"1","/Users/vmolina/Documents/ProjectsRedux/your-buddy/src/App.js":"2","/Users/vmolina/Documents/ProjectsRedux/your-buddy/src/reportWebVitals.js":"3","/Users/vmolina/Documents/ProjectsRedux/your-buddy/src/api/ChatAPI.js":"4"},{"size":500,"mtime":1611627447376,"results":"5","hashOfConfig":"6"},{"size":6322,"mtime":1611728893996,"results":"7","hashOfConfig":"6"},{"size":362,"mtime":1611627447377,"results":"8","hashOfConfig":"6"},{"size":846,"mtime":1611727261438,"results":"9","hashOfConfig":"6"},{"filePath":"10","messages":"11","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"12"},"melsa0",{"filePath":"13","messages":"14","errorCount":0,"warningCount":5,"fixableErrorCount":0,"fixableWarningCount":0,"source":"15"},{"filePath":"16","messages":"17","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"12"},{"filePath":"18","messages":"19","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},"/Users/vmolina/Documents/ProjectsRedux/your-buddy/src/index.js",[],["20","21"],"/Users/vmolina/Documents/ProjectsRedux/your-buddy/src/App.js",["22","23","24","25","26"],"import React, { useState, useEffect, useRef } from 'react';\nimport { animateScroll } from \"react-scroll\";\nimport './App.css';\n\nimport CC_LOGO from \"./images/cc.png\";\n\nconst API_KEY = process.env.REACT_APP_API_KEY;\n\nconst PREFIX = \"https://www.cleverbot.com/getreply\";\n\nclass ChatAPI {\n\n    /* Call back state for Cleverbot, needs to be passed back if set */\n    cs = null;\n\n    async getReply(input) {\n        /* Create base request */\n        let request = `${PREFIX}?key=${API_KEY}`;\n        \n        /* Add control state if present */\n        if (input !== \"\") {\n\n            /* Add input from user */\n            request += `&input=${encodeURIComponent(input)}`;\n        }\n\n        if (this.cs !== null) {\n            request += `&cs=${this.cs}`;\n        }\n\n        const response = await fetch(request);\n       \n        const json = await response.json();\n\n        /* Store control state */\n        this.cs = json.cs;\n\n        return json;\n    }\n}\n\nconst CHAT_API = new ChatAPI();\n\nfunction App() {\n  \n  const [voiceSynth, selectedVoiceSynth] = useState(window.speechSynthesis)\n  /* The text-to-speech voices available */\n  const [speechVoices, setSpeechVoices] = useState([]);\n\n  /* The current selected voice */\n  const [selectedVoice, setSelectedVoice] = useState(\"Google UK English Male\");\n\n  /* Flag to indicate if user is currently speaking */\n  const [isSpeaking, setIsSpeaking] = useState(false);\n\n  /* Ref to the recongnition object */\n  const recognition = useRef(null);\n\n  /* A list of recieved/sent messages */\n  const [messagesList, setMessagesList] = useState([]);\n\n  /* Flag to indicate waiting for response */\n  const [waitingForResponse, setWaitingForResponse] = useState(false);\n\n  /* Flag to show modal */\n  const [showInfoModal, setShowInfoModal] = useState(false);\n\n  /* On init */\n  useEffect(() => {\n    const voices = voiceSynth.getVoices();\n    console.log(voices);\n    /* Setup speech recognition */\n    recognition.current = new window.webkitSpeechRecognition();\n    recognition.current.continous = true;\n    // recognition.current.interimResults = true;\n    recognition.current.lang = 'en-US';\n\n    recognition.current.onstart = onRecognitionStart;\n    recognition.current.onspeechend = onSpeechEnd;\n    recognition.current.onresult = onRecognitionResult;\n\n    setSpeechVoices(voices);\n  }, []);\n\n  useEffect(() => {\n    if (isSpeaking) {\n      recognition.current.start();\n    } else {\n      recognition.current.stop();\n    }\n  }, [isSpeaking]);\n  \n  const getVoices = () => {\n    return speechVoices.map(voice => {\n      console.log(voice);\n\n      return (\n        <option key={voice.name} value={voice.name}>\n          {voice.name}\n        </option>\n      );\n    })\n  };\n  \n  useEffect(() => {\n    animateScroll.scrollToBottom({\n      containerId: \"messageContainer\",\n      duration: 200,\n      delay: 0\n    })\n  }, [messagesList])\n  const onVoiceStart = () => {\n    setIsSpeaking(!isSpeaking);\n  };\n\n  const onRecognitionStart = () => {\n    console.log(\"Listening to voice...\")\n  };\n\n  const onSpeechEnd = () => {\n    console.log(\"Stopped listening to voice\");\n    setIsSpeaking(false);\n  };\n\n  const capitalize = (s) => {\n    if (typeof s !== 'string') return ''\n    return s.charAt(0).toUpperCase() + s.slice(1)\n  }\n  const onRecognitionResult = (event) => {\n    console.log(\"Transcript: \", event.results[0][0].transcript);\n\n    /* Push the transcribed message to the list */\n    const message = {\n      type: \"sent\",\n      text: capitalize(event.results[0][0].transcript) + \".\"\n    };\n\n    setWaitingForResponse(true);\n  \n    CHAT_API.getReply(message.text)\n      .then((response) => {\n        const botResponse = {\n          type: \"recieved\",\n          text: response.output\n        }\n        \n        const utterThis = new SpeechSynthesisUtterance(botResponse.text);\n        const voice = speechVoices.find(el => \n          el.name === selectedVoice\n        );\n\n\n        utterThis.voice = voice;\n        voiceSynth.speak(utterThis);\n\n\n        setIsSpeaking(true);\n        setWaitingForResponse(false);\n        setMessagesList(oldMessages => [...oldMessages, botResponse]);\n      });\n\n    setIsSpeaking(false);\n    setMessagesList(oldMessages => [...oldMessages, message]);\n  };\n\n  const renderMessagesList = () => {\n    return messagesList.map((message) => {\n      \n      if (message.type === \"sent\") {\n        return (\n          <li className=\"message-list-message-container\">\n            <p className=\"user-message-label\">You said:</p>\n            <p className=\"message-text\">{message.text}</p>\n          </li>\n        );\n      }\n\n      if (message.type === \"recieved\") {\n        return (\n          <li className=\"message-list-message-container\">\n            <p className=\"bot-message-label\">Your bud said:</p>\n            <p className=\"message-text\">{message.text}</p>\n          </li>\n        )\n      }\n      \n    });\n  };\n\n  return (\n    <div className=\"App\">\n      {\n        showInfoModal && (\n          <div className=\"info-modal-container\">\n            <div className=\"info-modal\">\n              <h1>Buddy Talk</h1>\n              <p>Made possible by generous grants by the Coding Cougs.</p>\n              <img className=\"cc-logo-inner\" id=\"rotating\" src={CC_LOGO} alt=\"Coding Cougs logo\" />\n              <button onClick={() => setShowInfoModal(false)} className=\"cancel-btn\">Cancel</button>\n            </div>\n          </div> \n        )\n      }\n      <main className=\"text-box-container\">\n        {\n          messagesList.length === 0 ? (\n            <div className=\"empty-list-container\">\n              Start talking to your buddy by clicking the button below.\n            </div>\n          ) : (\n            <ul id=\"messageContainer\" className=\"message-box\">\n              {renderMessagesList()}\n            </ul>\n          )\n        }\n        \n      </main>\n\n      <div className=\"text-input-container\">\n        <div className=\"button-container\">\n\n          <button disabled={waitingForResponse} class={`${isSpeaking ? \"active\" : \"\"}`} onClick={onVoiceStart} id=\"getVoiceInputBtn\">\n            { isSpeaking ? \"Listening... click to stop\" : \"Click to start speaking\" }\n          </button>\n\n          <img class=\"cc-logo\" onClick={() => setShowInfoModal(true)} src={CC_LOGO} alt=\"Coding Cougs logo\" />\n        </div>\n      </div>\n    </div>\n  );\n}\n\n\n\nexport default App;\n","/Users/vmolina/Documents/ProjectsRedux/your-buddy/src/reportWebVitals.js",[],"/Users/vmolina/Documents/ProjectsRedux/your-buddy/src/api/ChatAPI.js",[],{"ruleId":"27","replacedBy":"28"},{"ruleId":"29","replacedBy":"30"},{"ruleId":"31","severity":1,"message":"32","line":46,"column":22,"nodeType":"33","messageId":"34","endLine":46,"endColumn":40},{"ruleId":"31","severity":1,"message":"35","line":51,"column":25,"nodeType":"33","messageId":"34","endLine":51,"endColumn":41},{"ruleId":"36","severity":1,"message":"37","line":83,"column":6,"nodeType":"38","endLine":83,"endColumn":8,"suggestions":"39"},{"ruleId":"31","severity":1,"message":"40","line":93,"column":9,"nodeType":"33","messageId":"34","endLine":93,"endColumn":18},{"ruleId":"41","severity":1,"message":"42","line":167,"column":39,"nodeType":"43","messageId":"44","endLine":167,"endColumn":41},"no-native-reassign",["45"],"no-negated-in-lhs",["46"],"no-unused-vars","'selectedVoiceSynth' is assigned a value but never used.","Identifier","unusedVar","'setSelectedVoice' is assigned a value but never used.","react-hooks/exhaustive-deps","React Hook useEffect has missing dependencies: 'onRecognitionResult' and 'voiceSynth'. Either include them or remove the dependency array.","ArrayExpression",["47"],"'getVoices' is assigned a value but never used.","array-callback-return","Array.prototype.map() expects a value to be returned at the end of arrow function.","ArrowFunctionExpression","expectedAtEnd","no-global-assign","no-unsafe-negation",{"desc":"48","fix":"49"},"Update the dependencies array to be: [onRecognitionResult, voiceSynth]",{"range":"50","text":"51"},[2324,2326],"[onRecognitionResult, voiceSynth]"]